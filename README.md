# Local Lakehouse-in-a-Repo (dbt + DuckDB + Python)

A fully local, reproducible **"lakehouse"** you can run on your laptop:

- **Bronze**: Parquet files in `data/raw/` (generated by Python)
- **Silver/Gold**: dbt models built into a local DuckDB database file: `duckdb/warehouse.duckdb`
- **Artifacts**: a small markdown report + charts, and dbt docs lineage

## Quickstart

### 1) Set up a virtual environment

```bash
python -m venv .venv
# Windows:
.\.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate
```

### 2) Install dependencies

```bash
pip install -r requirements.txt
```

### 3) Run the full demo

```bash
python run.py demo
```

Outputs:
- `duckdb/warehouse.duckdb` (tables built by dbt)
- `reports/outputs/report.md` (+ two PNG charts)
- `dbt/local_lakehouse/target/` (dbt docs artifacts)

## Explore the results

### Open the report
- `reports/outputs/report.md`

### Query DuckDB (Python)
```bash
python -c "import duckdb; print(duckdb.connect('duckdb/warehouse.duckdb').execute('select * from marts.mart_daily_kpis order by day desc limit 5').fetchdf())"
```

### View dbt lineage docs
```bash
cd dbt/local_lakehouse
dbt docs serve --profiles-dir ..
```

## Why this repo is useful in interviews

This is intentionally **portfolio-shaped**:
- clear bronze → staging → intermediate → marts layering
- real dbt tests + docs
- an incremental model (`marts.fct_pageviews_daily`)
- a snapshot (`snapshots.snap_customers`)
- a one-command runner (`python run.py demo`)
- CI-ready (see `.github/workflows/ci.yml`)

## Repo layout

```text
ingestion/                 # Python generates bronze Parquet files
data/raw/                  # Bronze data (gitignored; generated)
duckdb/                    # DuckDB warehouse file (generated)
dbt/local_lakehouse/        # dbt project (models/tests/macros/snapshots)
reports/                   # Python reads marts -> creates report artifacts
```

## Common commands

```bash
python run.py ingest
python run.py build
python run.py report
python run.py docs
python run.py clean
```

---

### Ideas to extend
- Add a dbt exposure that points at the markdown report or a dashboard
- Add a second incremental model (e.g., sessions)
- Add a simple Streamlit app that queries `marts.mart_daily_kpis`
- Swap synthetic data for a public dataset (NYC taxi, USGS earthquakes, etc.)
